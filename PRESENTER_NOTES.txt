================================================================================
ЗАМЕТКИ ДЛЯ ПРЕЗЕНТАЦИИ: Trustworthy AI Monitor
Промежуточное совещание - 25 ноября 2024
================================================================================

ВАЖНО: Это заметки для презентатора, а не текст слайдов. Используйте их как руководство при устном выступлении.

================================================================================
СЛАЙД 8: Существующие решения - Сравнение технологий
================================================================================

[ВСТУПЛЕНИЕ]
Здесь я хочу показать, что я изучил существующие решения и понимаю, какие технологии используются в индустрии для мониторинга ML-моделей.

[ЧТО МОНИТОРИТСЯ В СУЩЕСТВУЮЩИХ РЕШЕНИЯХ]

1. **Методы обнаружения дрифта данных:**
   - Статистические тесты: Kolmogorov-Smirnov (KS) тест - сравнивает распределения числовых признаков между обучающей и продакшн данными
   - Chi-Square тест - для категориальных признаков, проверяет изменения в частотах категорий
   - Population Stability Index (PSI) - метрика стабильности популяции, показывает насколько изменилось распределение
   - Wasserstein Distance - метрика расстояния между распределениями, более чувствительна к сдвигам
   - Детекторы на базе ML - используют обученные модели для обнаружения дрифта

2. **Мониторинг производительности:**
   - Отслеживание метрик во времени: accuracy, precision, recall, F1-score, ROC-AUC
   - Сравнение с базовыми показателями - устанавливается baseline при развертывании, затем текущие метрики сравниваются
   - Оповещения на основе порогов - если метрика падает более чем на 5% (warning) или 10% (critical), генерируется alert
   - Измерение задержки (latency) - среднее время предсказания, p95, p99 перцентили

3. **Метрики справедливости:**
   - Демографический паритет (Demographic Parity) - разница в частоте положительных предсказаний между группами
   - Равные возможности (Equal Opportunity) - разница в True Positive Rate между группами
   - Коэффициент несопоставимого воздействия (Disparate Impact) - отношение положительных предсказаний для защищенных групп

[КАК ЭТО МОНИТОРИТСЯ В РАЗНЫХ ПЛАТФОРМАХ]

**MLflow:**
- Фокусируется на отслеживании экспериментов и версионировании моделей
- Не имеет встроенного мониторинга дрифта или справедливости
- Требует интеграции с внешними инструментами

**Evidently AI:**
- Специализируется на обнаружении дрифта данных
- Использует статистические тесты (KS, Chi-square, PSI)
- Имеет визуализации, но требует отдельной настройки для справедливости

**Prometheus + Grafana:**
- Prometheus собирает метрики через HTTP endpoints
- Grafana визуализирует временные ряды
- Требует ручной настройки всех метрик и alerting правил
- Не имеет встроенных методов для дрифта или справедливости

**Наша система:**
- Объединяет все три аспекта в одной платформе
- Автоматически вычисляет все метрики
- Визуализация через Streamlit dashboard
- Оповещения в реальном времени прямо в интерфейсе

[ТЕХНИЧЕСКИЕ ДЕТАЛИ РЕАЛИЗАЦИИ]

В нашей системе мониторинг реализован следующим образом:

1. **Для дрифта данных:**
   - Класс `DriftDetector` в `src/monitoring/drift_metrics.py`
   - Принимает reference data (обучающая выборка) и current data (продакшн)
   - Для числовых признаков: KS-тест через `scipy.stats.ks_2samp()`
   - Для категориальных: Chi-square через `scipy.stats.chi2_contingency()`
   - PSI вычисляется вручную: биннинг данных, вычисление процентных изменений
   - Wasserstein distance через `scipy.stats.wasserstein_distance()`
   - Результаты возвращаются как словарь с p-values и флагами drift_detected

2. **Для производительности:**
   - Класс `PerformanceMonitor` в `src/monitoring/performance_metrics.py`
   - Вычисляет метрики через sklearn: `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_auc_score`
   - Latency измеряется через `time.time()` до и после `model.predict()` в цикле 100 итераций
   - Degradation detection: сравнивает текущие метрики с baseline, вычисляет relative change
   - Если relative change < -threshold (по умолчанию 5%), помечается как degraded

3. **Для справедливости:**
   - Класс `FairnessMonitor` в `src/monitoring/fairness_metrics.py`
   - Demographic Parity: группирует предсказания по sensitive feature, вычисляет mean положительных предсказаний, берет max - min
   - Equal Opportunity: для каждой группы вычисляет TPR = TP/(TP+FN), затем max - min
   - Disparate Impact: отношение min positive rate к max positive rate
   - Все метрики сравниваются с порогом (по умолчанию 0.1), если превышен - violation detected

================================================================================
СЛАЙД 9: Наш подход - Предлагаемое решение
================================================================================

[ОБЩИЙ ПОДХОД]
Здесь я объясняю, что мы создали интегрированную систему, которая объединяет все аспекты мониторинга в одной платформе.

[ЕДИНАЯ ПЛАТФОРМА]
- Все модули мониторинга работают вместе: performance, drift, fairness
- Единый API через FastAPI - можно вызывать все метрики через REST endpoints
- Streamlit dashboard показывает все метрики в одном интерфейсе
- Система оповещений (AlertManager) генерирует alerts для всех типов проблем
- Все результаты сохраняются в едином формате для анализа

[ОПТИМИЗАЦИЯ ДЛЯ CPU]
- Не используем GPU-зависимые библиотеки (например, TensorFlow/PyTorch для мониторинга)
- Все вычисления на NumPy, Pandas, scikit-learn - все работают на CPU
- XGBoost может использовать GPU, но мы используем CPU версию
- Энергоэффективно: можно запустить на обычном ноутбуке или сервере без GPU

[КОМПЛЕКСНЫЙ МОНИТОРИНГ]
- Performance: accuracy, precision, recall, F1, ROC-AUC, latency
- Drift: KS-test, Chi-square, PSI, Wasserstein для каждого признака
- Fairness: Demographic Parity, Equal Opportunity, Disparate Impact для каждой sensitive feature
- Все метрики вычисляются автоматически при вызове соответствующих функций

[ЧТО МЫ БУДЕМ МОНИТОРИТЬ И КАК МОДЕЛЬ ОБУЧЕНА ДЛЯ ЭТИХ МЕТРИК]

**1. Производительность модели:**
   - Модель обучается стандартным способом: XGBoost на предобработанных данных
   - После обучения вычисляются метрики на тестовой выборке: accuracy, precision, recall, F1, ROC-AUC
   - Эти метрики сохраняются как baseline
   - В продакшене: новые данные проходят через тот же preprocessor, модель делает предсказания
   - Метрики вычисляются на новых данных (если есть ground truth) или на предсказаниях
   - Сравнение с baseline показывает деградацию

**2. Дрифт данных:**
   - Модель обучается на reference data (обучающая выборка)
   - Preprocessor сохраняет статистики reference data (mean, std для числовых, value_counts для категориальных)
   - В продакшене: новые данные сравниваются с reference data через статистические тесты
   - Модель не переобучается, но мы обнаруживаем, что входные данные изменились
   - Это предупреждает о потенциальной деградации до того, как она произойдет

**3. Справедливость:**
   - Модель обучается на данных с демографическими признаками (sex, race)
   - После обучения анализируются предсказания для разных групп
   - Вычисляются fairness метрики: Demographic Parity, Equal Opportunity
   - В продакшене: новые предсказания анализируются на справедливость
   - Если метрики справедливости ухудшаются, генерируется alert

**Технические детали обучения:**
- Данные загружаются через `load_adult_data()` из OpenML
- Preprocessing через `DataPreprocessor`: 
  * Автоматическое определение числовых и категориальных признаков
  * Для числовых: SimpleImputer (заполнение пропусков средним), StandardScaler (нормализация)
  * Для категориальных: SimpleImputer (заполнение модой), OneHotEncoder (one-hot кодирование)
- Модель обучается через `ModelTrainer`: XGBoost с параметрами n_estimators=100, max_depth=6, learning_rate=0.1
- После обучения: модель и preprocessor сохраняются в pickle файлы
- Метрики вычисляются через `ModelEvaluator`: confusion matrix, все классификационные метрики

**По поводу augmentation:**
- В текущей реализации augmentation не используется, так как:
  * Adult Income dataset достаточно большой (~39K обучающих образцов)
  * Задача бинарной классификации, augmentation обычно используется для изображений
  * Для табличных данных augmentation менее распространен
- Однако, в коде есть функция `balance_dataset()` в `src/data/preprocess.py`, которая использует SMOTE для балансировки классов
- Это можно рассматривать как форму augmentation для minority class
- В будущих итерациях можно добавить другие методы augmentation для табличных данных (например, через библиотеку imblearn)

================================================================================
СЛАЙД 11: Описание данных - Набор данных Adult Income
================================================================================

[ЗАГРУЗКА И ХРАНЕНИЕ]
- Данные загружаются автоматически через OpenML API при первом запуске
- Используется функция `fetch_openml('adult', version=2)` из sklearn
- Данные кэшируются локально в `data/raw/adult.pkl` для быстрого доступа
- Если файл существует, загрузка из кэша, иначе из OpenML

[СТРУКТУРА ДАННЫХ]
- После загрузки данные разделяются на train/test (80/20) через `train_test_split`
- Обучающая выборка: ~39,000 образцов
- Тестовая выборка: ~9,700 образцов
- 14 признаков: смесь числовых и категориальных

[ПРИЗНАКИ]
- **Числовые:** age (возраст), fnlwgt (final weight), education-num (количество лет образования), capital-gain, capital-loss, hours-per-week
- **Категориальные:** workclass (тип работы), education (уровень образования), marital-status, occupation, relationship, race, sex, native-country

[ЦЕЛЕВАЯ ПЕРЕМЕННАЯ]
- Исходная: 'class' - строковые значения ">50K" или "<=50K"
- Преобразуется в бинарную: 1 если ">50K", 0 если "<=50K"
- Распределение классов несбалансированное: ~76% класса 0, ~24% класса 1
- Это важно для выбора метрик: F1-score лучше чем accuracy для несбалансированных данных

[ДЕМОГРАФИЧЕСКИЕ ПРИЗНАКИ]
- Sex: Male, Female - используется для анализа справедливости
- Race: White, Black, Asian-Pac-Islander, Amer-Indian-Eskimo, Other - также для справедливости
- Эти признаки позволяют анализировать, не дискриминирует ли модель определенные группы

[EDA (EXPLORATORY DATA ANALYSIS)]
В текущей реализации EDA выполняется автоматически при загрузке данных:

1. **Автоматическое определение типов признаков:**
   - `DataPreprocessor._detect_feature_types()` использует `select_dtypes()` для разделения на числовые и категориальные
   - Числовые: `include=['int64', 'float64']`
   - Категориальные: `include=['object', 'category', 'bool']`

2. **Анализ распределений:**
   - Для числовых: вычисляются mean, std, min, max, median, quartiles
   - Для категориальных: value_counts для частот категорий
   - Это используется в `DriftDetector._compute_statistics()` для reference data

3. **Обработка пропусков:**
   - Проверка на NaN значения
   - Для числовых: заполнение средним через SimpleImputer
   - Для категориальных: заполнение модой (most_frequent)

4. **Визуализация в Dashboard:**
   - В Data Explorer показывается `.describe()` для числовых признаков
   - Показывается sample данных
   - Можно посмотреть распределение классов

[ПРЕДОБРАБОТКА]
- Все происходит в классе `DataPreprocessor`
- Pipeline строится через sklearn `ColumnTransformer` и `Pipeline`
- Для числовых: Imputer → StandardScaler
- Для категориальных: Imputer → OneHotEncoder
- Preprocessor fit только на обучающей выборке, затем transform на тестовой
- Это важно для предотвращения data leakage

================================================================================
СЛАЙД 14: Описание данных - Конвейер обработки данных
================================================================================

[ШАГ 1: ЗАГРУЗКА ДАННЫХ]
- **Adult Income:** Автоматическая загрузка через `load_adult_data()`
  * Использует OpenML API: `fetch_openml('adult', version=2, as_frame=True)`
  * Сохраняет в кэш: `data/raw/adult.pkl`
  * Разделение на train/test происходит внутри функции через `train_test_split(test_size=0.2, random_state=42, stratify=y)`
  * Stratify=y обеспечивает одинаковое распределение классов в train и test

- **COMPAS:** Ручная загрузка
  * Пользователь должен скачать CSV файл с GitHub ProPublica
  * Разместить в `data/raw/compas-scores-two-years.csv`
  * Функция `load_compas_data()` читает CSV, обрабатывает колонки, создает target переменную

- **Синтетические данные:** Генерация по требованию
  * Функция `generate_synthetic_data()` использует `sklearn.datasets.make_classification()`
  * Параметры: n_samples=10000, n_features=10, n_informative=5, n_redundant=2
  * Опционально добавляются демографические признаки: age, gender, race
  * Все с фиксированным random_state=42 для воспроизводимости

[ШАГ 2: ПРЕДОБРАБОТКА]
Детальный процесс предобработки:

1. **Определение типов признаков:**
   - Автоматически через `_detect_feature_types()`
   - Если не указаны явно, определяются по dtypes DataFrame

2. **Обработка пропущенных значений:**
   - Для числовых: `SimpleImputer(strategy='mean')` - заполняет средним значением
   - Для категориальных: `SimpleImputer(strategy='most_frequent')` - заполняет наиболее частым значением
   - Это происходит ДО масштабирования/кодирования

3. **Масштабирование числовых признаков:**
   - `StandardScaler()` - стандартизация: (x - mean) / std
   - Приводит все числовые признаки к среднему 0 и стандартному отклонению 1
   - Важно для алгоритмов, чувствительных к масштабу (SVM, логистическая регрессия)
   - XGBoost менее чувствителен, но все равно полезно

4. **Кодирование категориальных признаков:**
   - `OneHotEncoder(handle_unknown='ignore', sparse_output=False)`
   - Создает бинарные колонки для каждой категории
   - Например, если race имеет 5 категорий, создается 5 новых колонок
   - `handle_unknown='ignore'` обрабатывает новые категории в тестовых данных (ставит все 0)

5. **Объединение:**
   - `ColumnTransformer` объединяет числовой и категориальный pipelines
   - Результат: один массив с числовыми признаками + one-hot encoded категориальные

6. **Сохранение feature names:**
   - После трансформации вычисляются имена признаков через `_compute_feature_names()`
   - Для числовых: исходные имена сохраняются
   - Для категориальных: имена вида "race_White", "race_Black" и т.д.

[ШАГ 3: ХРАНЕНИЕ]
- **Сырые данные:** `data/raw/` - оригинальные данные до предобработки
- **Обработанные данные:** `data/processed/` - можно сохранить предобработанные данные для быстрого доступа
- **Синтетические:** Генерируются в памяти, но можно сохранить при необходимости

[ШАГ 4: ОБУЧЕНИЕ МОДЕЛИ]
Процесс обучения:

1. **Инициализация ModelTrainer:**
   - Выбирается тип модели: 'xgboost', 'random_forest', 'logistic', 'lightgbm', 'svm'
   - Устанавливаются гиперпараметры (можно переопределить defaults)
   - Random state фиксируется для воспроизводимости

2. **Обучение:**
   - `trainer.train(X_train_processed, y_train)`
   - Для XGBoost: используется `.fit()` с указанными параметрами
   - Параметры по умолчанию: n_estimators=100, max_depth=6, learning_rate=0.1
   - Можно добавить validation set для early stopping (не реализовано в текущей версии)

3. **Оценка:**
   - После обучения модель оценивается на тестовой выборке
   - `ModelEvaluator` вычисляет все метрики: accuracy, precision, recall, F1, ROC-AUC
   - Строится confusion matrix для визуализации

4. **Сохранение:**
   - Модель: `joblib.dump(model, 'models/trained_model.pkl')`
   - Preprocessor: `joblib.dump(preprocessor, 'models/preprocessor.pkl')`
   - Результаты: сохраняются в CSV файл с метриками

[ВАЖНЫЕ МОМЕНТЫ]
- Preprocessor fit ТОЛЬКО на обучающей выборке
- Тестовая выборка transform без fit - это критично для правильной оценки
- Все random states фиксированы (42) для воспроизводимости
- Модель и preprocessor сохраняются вместе - они должны использоваться вместе

================================================================================
СЛАЙД 17: Обновление прогресса - Рабочий пример
================================================================================

[РЕАЛЬНЫЕ РЕЗУЛЬТАТЫ]
Здесь я показываю конкретные результаты, которые я получил, запустив систему.

[ПРОИЗВОДИТЕЛЬНОСТЬ МОДЕЛИ]
- **Точность: 87.45%** - это accuracy на тестовой выборке
  * Это означает, что модель правильно классифицирует 87.45% образцов
  * Для несбалансированных данных это хороший результат, но не единственный показатель

- **F1-оценка: 70.89%** - более важная метрика для несбалансированных данных
  * F1 = 2 * (precision * recall) / (precision + recall)
  * Учитывает и precision, и recall
  * 70.89% - это хороший результат, показывает, что модель хорошо работает с minority class

- **ROC AUC: 92.90%** - отличный результат
  * Показывает способность модели различать классы
  * AUC > 0.9 считается отличным
  * Это означает, что модель хорошо разделяет два класса

[КАК ЭТИ МЕТРИКИ ВЫЧИСЛЯЮТСЯ]
1. Модель делает предсказания на тестовой выборке: `y_pred = model.predict(X_test)`
2. Если модель поддерживает probabilities: `y_proba = model.predict_proba(X_test)[:, 1]`
3. Accuracy: `accuracy_score(y_test, y_pred)` - доля правильных предсказаний
4. Precision: `precision_score(y_test, y_pred)` - из всех положительных предсказаний, сколько правильных
5. Recall: `recall_score(y_test, y_pred)` - из всех реальных положительных, сколько найдено
6. F1: `f1_score(y_test, y_pred)` - гармоническое среднее precision и recall
7. ROC AUC: `roc_auc_score(y_test, y_proba)` - площадь под ROC кривой

[ФУНКЦИОНАЛЬНОСТЬ СИСТЕМЫ]
- **Dashboard на localhost:8501:**
  * Запускается через `streamlit run src/dashboard/dashboard.py`
  * Показывает все страницы: Data Explorer, Model Training, Performance Monitoring, Drift Detection, Fairness Analysis, Live Predictions
  * Все визуализации через Plotly - интерактивные графики
  * Система оповещений показывает alerts в реальном времени

- **API endpoints:**
  * FastAPI сервер можно запустить через `uvicorn src.api.main:app`
  * Endpoints: `/predict`, `/monitor/performance`, `/monitor/drift`, `/monitor/fairness`
  * Все возвращают JSON с результатами
  * Можно интегрировать с внешними системами

- **Система оповещений:**
  * `AlertManager` генерирует alerts при обнаружении проблем
  * Severity levels: Critical (красный), Warning (желтый), Info (синий), Success (зеленый)
  * Оповещения показываются в dashboard и в sidebar
  * Можно настроить пороги для каждого типа alert

- **Все модули мониторинга работают:**
  * PerformanceMonitor - вычисляет метрики и обнаруживает деградацию
  * DriftDetector - обнаруживает дрифт данных через статистические тесты
  * FairnessMonitor - анализирует справедливость для разных групп
  * Все интегрированы в dashboard и API

[СГЕНЕРИРОВАННЫЕ АРТЕФАКТЫ]
- **models/trained_model.pkl:**
  * Обученная XGBoost модель
  * Можно загрузить через `joblib.load()`
  * Используется для предсказаний в продакшене

- **models/preprocessor.pkl:**
  * Обученный preprocessor с сохраненными статистиками
  * Должен использоваться вместе с моделью
  * Обеспечивает одинаковую предобработку для новых данных

- **results/first_model_results.csv:**
  * CSV файл с метриками: accuracy, precision, recall, f1, roc_auc
  * Можно использовать для сравнения с будущими моделями
  * Формат позволяет легко анализировать результаты

[ИТЕРАЦИИ ИССЛЕДОВАНИЙ - ОТВЕТ НА ЗАМЕЧАНИЕ ЖЮРИ]

Важное замечание жюри было: "нужно четко зафиксировать итерации исследований. есть риск всё не успеть, поэтому нужен четкий алгоритм проведения экспериментов и исследований."

**Я зафиксировал 6 итераций исследований:**

**Итерация 1: Базовые эксперименты с данными и моделями (2-3 недели) - ✅ ЗАВЕРШЕНА**
- Загружен Adult Income dataset
- Реализована предобработка данных
- Обучена первая модель (XGBoost)
- Получены начальные метрики производительности
- **Результат:** Базовая модель с метриками (accuracy 87.45%, F1 70.89%, ROC AUC 92.90%)

**Итерация 2: Реализация обнаружения дрифта (2-3 недели) - ✅ ЗАВЕРШЕНА**
- Реализованы методы обнаружения дрифта: PSI, KS-test, Chi-square, Wasserstein
- Протестировано на синтетических данных с дрифтом
- Сравнение методов при разных интенсивностях дрифта (0.1, 0.3, 0.5)
- **Результат:** Работающий DriftDetector с визуализациями в dashboard

**Итерация 3: Мониторинг производительности (2-3 недели) - ✅ ЗАВЕРШЕНА**
- Реализован PerformanceMonitor
- Симуляция постепенной деградации
- Отслеживание метрик во времени
- Обнаружение деградации с порогами (5% warning, 10% critical)
- **Результат:** Работающий мониторинг производительности с alerts

**Итерация 4: Анализ справедливости (2-3 недели) - ✅ ЗАВЕРШЕНА**
- Реализованы метрики справедливости: Demographic Parity, Equal Opportunity
- Анализ на Adult Income dataset (по признакам sex и race)
- Метрики производительности по группам
- **Результат:** Работающий FairnessMonitor с анализом по группам

**Итерация 5: Интеграция и end-to-end тестирование (2-3 недели) - ✅ В ПРОЦЕССЕ**
- Интеграция всех компонентов в единую систему
- Тестирование полного pipeline: данные → модель → мониторинг
- Тестирование API
- Интеграция с dashboard
- **Текущий статус:** Все модули работают, dashboard функционален, API готов

**Итерация 6: Финальная валидация (1-2 недели) - ⏳ ЗАПЛАНИРОВАНА**
- Сравнение с существующими решениями
- Финальные эксперименты
- Подготовка презентации
- **План:** Завершить к концу декабря

**Алгоритм проведения экспериментов:**

Для каждой итерации:
1. **Цель:** Четко определить, что нужно достичь
2. **Гипотеза:** Сформулировать гипотезу для проверки
3. **Методология:** Пошаговый протокол эксперимента
4. **Реализация:** Написание кода и тестирование
5. **Результаты:** Метрики, визуализации, выводы
6. **Документация:** Запись результатов и выводов

**Контроль времени:**
- Каждая итерация ограничена 2-3 неделями
- Если не укладываемся - приоритизируем MVP функциональность
- Документируем что сделано, что осталось
- Регулярные промежуточные совещания для корректировки плана

================================================================================
КОНЕЦ ЗАМЕТОК ДЛЯ ПРЕЗЕНТАЦИИ
================================================================================

